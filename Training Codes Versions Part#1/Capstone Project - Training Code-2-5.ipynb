{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6cb91ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 11:15:21 WARN Utils: Your hostname, Naifs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "24/10/22 11:15:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/n7/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/n7/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-76db8f6e-cae7-4d3a-9f90-9f16896355cf;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.2.0 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/n7/Programs/anaconda3/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.375 in central\n",
      ":: resolution report :: resolve 89ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.375 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-76db8f6e-cae7-4d3a-9f90-9f16896355cf\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "24/10/22 11:15:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully!\n",
      "Building TF-IDF vocabulary...\n",
      "TF-IDF vocabulary built successfully.\n",
      "TF-IDF model saved successfully.\n",
      "Processing batch number: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/n7/Programs/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/22 11:16:07 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/10/22 11:16:07 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 0\n",
      "\n",
      "Processing batch number: 1\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 1\n",
      "\n",
      "Processing batch number: 2\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 2\n",
      "\n",
      "Processing batch number: 3\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 3\n",
      "\n",
      "Processing batch number: 4\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 4\n",
      "\n",
      "Processing batch number: 5\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 5\n",
      "\n",
      "Processing batch number: 6\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 6\n",
      "\n",
      "Processing batch number: 7\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 7\n",
      "\n",
      "Processing batch number: 8\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 8\n",
      "\n",
      "Processing batch number: 9\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 9\n",
      "\n",
      "Processing batch number: 10\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 10\n",
      "\n",
      "Processing batch number: 11\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 11\n",
      "\n",
      "Processing batch number: 12\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 12\n",
      "\n",
      "Processing batch number: 13\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 13\n",
      "\n",
      "Processing batch number: 14\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 14\n",
      "\n",
      "Processing batch number: 15\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 15\n",
      "\n",
      "Processing batch number: 16\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 16\n",
      "\n",
      "Processing batch number: 17\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 17\n",
      "\n",
      "Processing batch number: 18\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 18\n",
      "\n",
      "Processing batch number: 19\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 19\n",
      "\n",
      "Processing batch number: 20\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 20\n",
      "\n",
      "Processing batch number: 21\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 21\n",
      "\n",
      "Processing batch number: 22\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 22\n",
      "\n",
      "Processing batch number: 23\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 23\n",
      "\n",
      "Processing batch number: 24\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 24\n",
      "\n",
      "Processing batch number: 25\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 25\n",
      "\n",
      "Processing batch number: 26\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 26\n",
      "\n",
      "Processing batch number: 27\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 27\n",
      "\n",
      "Processing batch number: 28\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 28\n",
      "\n",
      "Processing batch number: 29\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 29\n",
      "\n",
      "Processing batch number: 30\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 30\n",
      "\n",
      "Processing batch number: 31\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 31\n",
      "\n",
      "Processing batch number: 32\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 32\n",
      "\n",
      "Processing batch number: 33\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 33\n",
      "\n",
      "Processing batch number: 34\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 34\n",
      "\n",
      "Processing batch number: 35\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 35\n",
      "\n",
      "Processing batch number: 36\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 36\n",
      "\n",
      "Processing batch number: 37\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 37\n",
      "\n",
      "Processing batch number: 38\n",
      "Mini-Batch KMeans Model Updated and Saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model for batch trained successfully\n",
      "Word2Vec Model Updated and Saved successfully\n",
      "Finished processing batch number: 38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged ALS User and Item Factors Saved successfully\n",
      "All Models Updated and Saved successfully\n",
      "Training Completed and models were saved successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import lit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import joblib\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# ----------- Step 1: Spark Session Initialization -----------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NewsRecommendationALS\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.executor.memory\", \"20g\") \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .config(\"spark.hadoop.hadoop.security.authentication\", \"simple\") \\\n",
    "    .config(\"spark.hadoop.hadoop.security.authorization\", \"false\") \\\n",
    "    .config(\"spark.network.timeout\", \"2000s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"200s\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.0\") \\\n",
    "    .config(\"spark.executor.extraLibraryPath\", \"/opt/homebrew/opt/openblas/lib\") \\\n",
    "    .config(\"spark.driver.extraLibraryPath\", \"/opt/homebrew/opt/openblas/lib\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")  # Reduce log verbosity\n",
    "print(\"Spark session created successfully!\")\n",
    "\n",
    "save_dir = '/Users/n7/Desktop/ie University SAMBD Acadamics/Capstone Project/Machine Learning Codes/Trained Models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# ----------- Step 2: Load News and Behavior Datasets in Batches -----------\n",
    "batch_size = 2500  # Reduced batch size to minimize memory issues\n",
    "\n",
    "news_file_path = '/Users/n7/Desktop/ie University SAMBD Acadamics/Capstone Project/Data/MINDlarge_train/Cleaned Datasets/News_cleaned.csv'\n",
    "news_columns = [\n",
    "    \"News ID\", \"Category\", \"Subcategory\", \"Title\", \"Abstract\", \"URL\", \"Entities Mentioned\", \"Entities in Abstract\"\n",
    "]\n",
    "news_df_iterator = pd.read_csv(news_file_path, sep=',', names=news_columns, chunksize=batch_size)\n",
    "\n",
    "behavior_file_path = '/Users/n7/Desktop/ie University SAMBD Acadamics/Capstone Project/Data/MINDlarge_train/Cleaned Datasets/cleaned_behavior_dataset.csv'\n",
    "behavior_columns = [\n",
    "    \"Impression ID\", \"User ID\", \"Timestamp\", \"Displayed News List\", \"Impression List (Clicked Status)\",\n",
    "    \"Impression Dictionary\", \"Clicked News IDs\", \"Not-Clicked News IDs\"\n",
    "]\n",
    "behavior_df_iterator = pd.read_csv(behavior_file_path, sep=',', names=behavior_columns, chunksize=batch_size)\n",
    "\n",
    "# ----------- Step 3: Initialize Label Encoders for User ID and News ID -----------\n",
    "user_encoder = LabelEncoder()\n",
    "news_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoders on complete datasets (to ensure consistency across batches)\n",
    "user_ids = []\n",
    "news_ids = []\n",
    "for behavior_df in behavior_df_iterator:\n",
    "    user_ids.extend(behavior_df['User ID'].unique())\n",
    "    news_ids.extend(behavior_df['Clicked News IDs'].str.split(',').explode().dropna().unique())\n",
    "    news_ids.extend(behavior_df['Not-Clicked News IDs'].str.split(',').explode().dropna().unique())\n",
    "\n",
    "user_encoder.fit(user_ids)\n",
    "news_encoder.fit(news_ids)\n",
    "\n",
    "# Restart iterators after fitting label encoders\n",
    "behavior_df_iterator = pd.read_csv(behavior_file_path, sep=',', names=behavior_columns, chunksize=batch_size)\n",
    "news_df_iterator = pd.read_csv(news_file_path, sep=',', names=news_columns, chunksize=batch_size)\n",
    "\n",
    "# ----------- Step 4: Counter Function -----------\n",
    "# Simple batch counter function\n",
    "def batch_counter(start=0):\n",
    "    count = start\n",
    "    while True:\n",
    "        yield count\n",
    "        count += 1\n",
    "\n",
    "# Create an instance of the counter generator\n",
    "counter = batch_counter()\n",
    "\n",
    "# Initialize MiniBatchKMeans for incremental learning\n",
    "best_k = 70\n",
    "mini_batch_kmeans = MiniBatchKMeans(n_clusters=best_k, batch_size=500, random_state=42)\n",
    "\n",
    "# Initialize Word2Vec model for incremental training\n",
    "word2vec_model = Word2Vec(vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# First pass to build TF-IDF vocabulary\n",
    "print(\"Building TF-IDF vocabulary...\")\n",
    "all_text = []\n",
    "for news_df in news_df_iterator:\n",
    "    news_df['Text'] = news_df['Category'] + \" \" + news_df['Subcategory'] + \" \" + news_df['Title'] + \" \" + news_df['Abstract']\n",
    "    all_text.extend(news_df['Text'].values)\n",
    "\n",
    "# Initialize and fit the TF-IDF vectorizer to build a global vocabulary\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(all_text)\n",
    "print(\"TF-IDF vocabulary built successfully.\")\n",
    "\n",
    "# Save the TF-IDF vectorizer with the complete vocabulary for reuse\n",
    "joblib.dump(vectorizer, os.path.join(save_dir, 'tfidf_vectorizer.pkl'))\n",
    "print(\"TF-IDF model saved successfully.\")\n",
    "\n",
    "# Restart the news iterator for processing batches\n",
    "news_df_iterator = pd.read_csv(news_file_path, sep=',', names=news_columns, chunksize=batch_size)\n",
    "\n",
    "# ----------- Step 5: Model Averaging Variables -----------\n",
    "user_factors_dict = {}\n",
    "item_factors_dict = {}\n",
    "batch_count = 0\n",
    "\n",
    "# ----------- Step 6: Process Each Batch -----------\n",
    "for news_df, behavior_df in zip(news_df_iterator, behavior_df_iterator):\n",
    "    \n",
    "    batch_number = next(counter)\n",
    "    print(f\"Processing batch number: {batch_number}\")\n",
    "    \n",
    "    # ----------- Preprocess the News Dataset (for Content-Based Filtering) -----------\n",
    "    news_df['Text'] = news_df['Category'] + \" \" + news_df['Subcategory'] + \" \" + news_df['Title'] + \" \" + news_df['Abstract']\n",
    "\n",
    "    # Transform the text using the pre-built TF-IDF vectorizer (Incremental transformation using pre-built vocabulary)\n",
    "    tfidf_matrix = vectorizer.transform(news_df['Text'])\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    # ----------- Word2Vec for News Embedding (Initial Training and Incremental Training) -----------\n",
    "    sentences = [text.split() for text in news_df['Text']]\n",
    "    if batch_number == 0:\n",
    "        word2vec_model.build_vocab(sentences)\n",
    "    else:\n",
    "        word2vec_model.build_vocab(sentences, update=True)\n",
    "    \n",
    "    word2vec_model.train(sentences, total_examples=len(sentences), epochs=5)\n",
    "\n",
    "    def get_article_embedding(text):\n",
    "        words = text.split()\n",
    "        word_vecs = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "        return np.mean(word_vecs, axis=0).astype(np.float32) if word_vecs else np.zeros(100, dtype=np.float32)\n",
    "\n",
    "    news_df['Article Embedding'] = news_df['Text'].apply(get_article_embedding)\n",
    "\n",
    "    # ----------- Mini-Batch KMeans Clustering (Incremental Update) -----------\n",
    "    news_embeddings = np.vstack(news_df['Article Embedding'].values)\n",
    "    mini_batch_kmeans.partial_fit(news_embeddings)\n",
    "\n",
    "    joblib.dump(mini_batch_kmeans, os.path.join(save_dir, f'mini_batch_kmeans_news_model.pkl'))\n",
    "    print(\"Mini-Batch KMeans Model Updated and Saved successfully\")\n",
    "\n",
    "    # ----------- ALS (Collaborative Filtering) for Clicked and Not-Clicked News -----------\n",
    "    clicked_df = behavior_df[['User ID', 'Clicked News IDs']].copy()\n",
    "    clicked_df = clicked_df.assign(Clicked_News=clicked_df['Clicked News IDs'].str.split(',')).explode('Clicked_News').drop(columns='Clicked News IDs')\n",
    "    clicked_df['Clicked_News'] = clicked_df['Clicked_News'].astype(str)\n",
    "\n",
    "    not_clicked_df = behavior_df[['User ID', 'Not-Clicked News IDs']].copy()\n",
    "    not_clicked_df = not_clicked_df.assign(Not_Clicked_News=not_clicked_df['Not-Clicked News IDs'].str.split(',')).explode('Not_Clicked_News').drop(columns='Not-Clicked News IDs')\n",
    "    not_clicked_df['Not_Clicked_News'] = not_clicked_df['Not_Clicked_News'].astype(str)\n",
    "\n",
    "    # Encode User ID and News ID using the fitted label encoders\n",
    "    clicked_df['User ID'] = user_encoder.transform(clicked_df['User ID'])\n",
    "    clicked_df['Clicked_News'] = news_encoder.transform(clicked_df['Clicked_News'])\n",
    "    not_clicked_df['User ID'] = user_encoder.transform(not_clicked_df['User ID'])\n",
    "    not_clicked_df['Not_Clicked_News'] = news_encoder.transform(not_clicked_df['Not_Clicked_News'])\n",
    "\n",
    "    clicked_spark_df = spark.createDataFrame(clicked_df.dropna())\n",
    "    not_clicked_spark_df = spark.createDataFrame(not_clicked_df.dropna())\n",
    "\n",
    "    clicked_spark_df = clicked_spark_df.withColumn('rating', lit(1.0))\n",
    "    not_clicked_spark_df = not_clicked_spark_df.withColumn('rating', lit(0.0))\n",
    "\n",
    "    combined_behavior_spark_df = clicked_spark_df.union(\n",
    "        not_clicked_spark_df.withColumnRenamed('Not_Clicked_News', 'Clicked_News')\n",
    "    ).withColumnRenamed('Clicked_News', 'News ID')\n",
    "    \n",
    "    # Repartition the DataFrame to increase parallelism and improve performance\n",
    "    combined_behavior_spark_df = combined_behavior_spark_df.repartition(200)\n",
    "\n",
    "    # ALS model initialization and training\n",
    "    als = ALS(userCol=\"User ID\", itemCol=\"News ID\", ratingCol=\"rating\", implicitPrefs=True, coldStartStrategy=\"drop\",\n",
    "              rank=10, maxIter=10, regParam=0.1)\n",
    "\n",
    "    try:\n",
    "        als_model = als.fit(combined_behavior_spark_df)\n",
    "        user_factors = als_model.userFactors.collect()\n",
    "        item_factors = als_model.itemFactors.collect()\n",
    "\n",
    "        # Accumulate user and item factors in dictionaries\n",
    "        for row in user_factors:\n",
    "            user_id = row['id']\n",
    "            features = np.array(row['features'], dtype=np.float32)\n",
    "            if user_id in user_factors_dict:\n",
    "                user_factors_dict[user_id] += features\n",
    "            else:\n",
    "                user_factors_dict[user_id] = features\n",
    "\n",
    "        for row in item_factors:\n",
    "            item_id = row['id']\n",
    "            features = np.array(row['features'], dtype=np.float32)\n",
    "            if item_id in item_factors_dict:\n",
    "                item_factors_dict[item_id] += features\n",
    "            else:\n",
    "                item_factors_dict[item_id] = features\n",
    "\n",
    "        batch_count += 1\n",
    "        print(\"ALS Model for batch trained successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to train ALS model for batch {batch_number}: {e}\")\n",
    "\n",
    "    # Save other models for future use\n",
    "    word2vec_model.save(os.path.join(save_dir, 'word2vec_model.model'))\n",
    "    print(\"Word2Vec Model Updated and Saved successfully\")\n",
    "\n",
    "    print(f\"Finished processing batch number: {batch_number}\\n\")\n",
    "\n",
    "# ----------- Step 7: Average Latent Factors and Save Final Model -----------\n",
    "if batch_count > 0:\n",
    "    # Average user and item factors\n",
    "    user_factors_avg = {user_id: features / batch_count for user_id, features in user_factors_dict.items()}\n",
    "    item_factors_avg = {item_id: features / batch_count for item_id, features in item_factors_dict.items()}\n",
    "    \n",
    "    # Save user and item factors separately\n",
    "    user_factors_avg_df = spark.createDataFrame([(user_id, [float(f) for f in features]) for user_id, features in user_factors_avg.items()], [\"user_id\", \"user_features\"])\n",
    "    item_factors_avg_df = spark.createDataFrame([(item_id, [float(f) for f in features]) for item_id, features in item_factors_avg.items()], [\"item_id\", \"item_features\"])\n",
    "    \n",
    "    user_factors_avg_df.write.mode(\"overwrite\").parquet(os.path.join(save_dir, 'als_user_factors_avg.parquet'))\n",
    "    item_factors_avg_df.write.mode(\"overwrite\").parquet(os.path.join(save_dir, 'als_item_factors_avg.parquet'))\n",
    "    \n",
    "    print(\"Averaged ALS User and Item Factors Saved successfully\")\n",
    "    print(\"All Models Updated and Saved successfully\")\n",
    "\n",
    "print(\"Training Completed and models were saved successfully\")\n",
    "# ----------- End -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac58a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
